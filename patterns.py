import pandas as pd
import numpy as np
import talib
from datetime import datetime
import logging
from typing import Dict, List, Optional, Tuple
import warnings

warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)


class PatternDetector:
    """
    –î–µ—Ç–µ–∫—Ç–æ—Ä –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    –†–µ–∞–ª–∏–∑—É–µ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ü–µ–Ω–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    """

    def __init__(self):
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.pattern_config = {
            'head_shoulders': {
                'min_peaks': 3,
                'peak_distance': 5,
                'height_variation': 0.05
            },
            'double_top_bottom': {
                'price_tolerance': 0.02,
                'time_tolerance': 15,
                'min_time_gap': 5
            },
            'triangle': {
                'convergence_threshold': 0.001,
                'min_bars': 10
            },
            'candlestick': {
                'shadow_ratio': 0.6,
                'body_ratio': 0.3
            }
        }

        # –û–ø–∏—Å–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π
        self.pattern_descriptions = {
            '–ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏': {
                'type': '–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π',
                'trend': '–ú–µ–¥–≤–µ–∂–∏–π',
                'description': '–°–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä–µ—Ö –≤–µ—Ä—à–∏–Ω: –ª–µ–≤–æ–µ –ø–ª–µ—á–æ, –≥–æ–ª–æ–≤–∞ (—Å–∞–º–∞—è –≤—ã—Å–æ–∫–∞—è), –ø—Ä–∞–≤–æ–µ –ø–ª–µ—á–æ. –õ–∏–Ω–∏—è —à–µ–∏ —Å–æ–µ–¥–∏–Ω—è–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω–∏—è –º–µ–∂–¥—É –≤–µ—Ä—à–∏–Ω–∞–º–∏.',
                'reliability': '–í—ã—Å–æ–∫–∞—è',
                'volume': '–£–º–µ–Ω—å—à–∞–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—à–∏–Ω–µ',
                'target': '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –≥–æ–ª–æ–≤—ã –¥–æ –ª–∏–Ω–∏–∏ —à–µ–∏',
                'confirmation': '–ü—Ä–æ–±–æ–π –ª–∏–Ω–∏–∏ —à–µ–∏ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –æ–±—ä–µ–º–∞'
            },
            '–î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞': {
                'type': '–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π',
                'trend': '–ú–µ–¥–≤–µ–∂–∏–π',
                'description': '–î–≤–µ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã –ø–æ—Å–ª–µ –≤–æ—Å—Ö–æ–¥—è—â–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞. –§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–∏.',
                'reliability': '–°—Ä–µ–¥–Ω—è—è',
                'volume': '–û–±—ã—á–Ω–æ –Ω–∏–∂–µ –Ω–∞ –≤—Ç–æ—Ä–æ–π –≤–µ—Ä—à–∏–Ω–µ',
                'target': '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –≤–µ—Ä—à–∏–Ω –¥–æ —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
                'confirmation': '–ü—Ä–æ–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –≤–µ—Ä—à–∏–Ω–∞–º–∏'
            },
            '–î–≤–æ–π–Ω–æ–µ –¥–Ω–æ': {
                'type': '–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π',
                'trend': '–ë—ã—á–∏–π',
                'description': '–î–≤–µ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω—ã–µ –≤–ø–∞–¥–∏–Ω—ã –ø–æ—Å–ª–µ –Ω–∏—Å—Ö–æ–¥—è—â–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞. –§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–µ.',
                'reliability': '–°—Ä–µ–¥–Ω—è—è',
                'volume': '–û–±—ã—á–Ω–æ –≤—ã—à–µ –Ω–∞ –≤—Ç–æ—Ä–æ–º –¥–Ω–µ',
                'target': '–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –≤–ø–∞–¥–∏–Ω –¥–æ —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è',
                'confirmation': '–ü—Ä–æ–±–æ–π —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è –º–µ–∂–¥—É –≤–ø–∞–¥–∏–Ω–∞–º–∏'
            },
            '–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫': {
                'type': '–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ',
                'trend': '–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–æ—è',
                'description': '–°—Ö–æ–¥—è—â–∏–µ—Å—è –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è. –û–±—ä–µ–º —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏.',
                'reliability': '–í—ã—Å–æ–∫–∞—è',
                'volume': '–£–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞, —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø—Ä–æ–±–æ–µ',
                'target': '–í—ã—Å–æ—Ç–∞ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞ –≤ –Ω–∞—á–∞–ª–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è',
                'confirmation': '–ü—Ä–æ–±–æ–π –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —Ç—Ä–µ–Ω–¥–∞ —Å –æ–±—ä–µ–º–æ–º'
            }
        }

    def detect_patterns(self, market_data: pd.DataFrame) -> List[Dict]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if market_data is None or len(market_data) < 50:
            return []

        patterns = []

        try:
            # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            patterns.extend(self._detect_reversal_patterns(market_data))
            patterns.extend(self._detect_continuation_patterns(market_data))
            patterns.extend(self._detect_candlestick_patterns(market_data))

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ —Å–ª–∞–±—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            patterns = self._filter_patterns(patterns)

            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            return patterns

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return []

    def _detect_reversal_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        patterns = []

        # –ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏
        hs_pattern = self._detect_head_shoulders(df)
        if hs_pattern:
            patterns.append(hs_pattern)

        # –î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞/–¥–Ω–æ
        dt_pattern = self._detect_double_top_bottom(df)
        if dt_pattern:
            patterns.append(dt_pattern)

        return patterns

    def _detect_continuation_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞"""
        patterns = []

        # –¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏
        triangle_pattern = self._detect_triangle_patterns(df)
        if triangle_pattern:
            patterns.append(triangle_pattern)

        # –§–ª–∞–≥–∏ –∏ –≤—ã–º–ø–µ–ª—ã
        flag_pattern = self._detect_flag_pennant(df)
        if flag_pattern:
            patterns.append(flag_pattern)

        return patterns

    def _detect_candlestick_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤–µ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        patterns = []

        # –ú–æ–ª–æ—Ç –∏ –ø–æ–≤–µ—à–µ–Ω–Ω—ã–π
        hammer_pattern = self._detect_hammer_hanging_man(df)
        if hammer_pattern:
            patterns.append(hammer_pattern)

        # –ü–æ–≥–ª–æ—â–µ–Ω–∏–µ
        engulfing_pattern = self._detect_engulfing_patterns(df)
        if engulfing_pattern:
            patterns.append(engulfing_pattern)

        # –î–æ–¥–∂–∏
        doji_pattern = self._detect_doji_patterns(df)
        if doji_pattern:
            patterns.append(doji_pattern)

        return patterns

    def _detect_head_shoulders(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ '–ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏'
        üîç –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç: –ò—â–µ–º —Ç—Ä–∏ –≤–µ—Ä—à–∏–Ω—ã, –≥–¥–µ —Å—Ä–µ–¥–Ω—è—è (–≥–æ–ª–æ–≤–∞) –≤—ã—à–µ –¥–≤—É—Ö –¥—Ä—É–≥–∏—Ö (–ø–ª–µ—á)
        """
        try:
            if len(df) < 30:
                return None

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≥–ª–∞–∂–µ–Ω–Ω—ã–µ —Ü–µ–Ω—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∏–∫–æ–≤
            close_prices = df['close'].values[-50:]
            high_prices = df['high'].values[-50:]

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –ø–∏–∫–∏
            peaks = []
            for i in range(5, len(high_prices) - 5):
                if (high_prices[i] > np.max(high_prices[i - 5:i]) and
                        high_prices[i] > np.max(high_prices[i + 1:i + 6])):
                    peaks.append((i, high_prices[i]))

            if len(peaks) < 3:
                return None

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∏–∫–∏ –ø–æ –≤—ã—Å–æ—Ç–µ
            peaks.sort(key=lambda x: x[1], reverse=True)

            # –ì–æ–ª–æ–≤–∞ - —Å–∞–º–∞—è –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä—à–∏–Ω–∞
            head_idx, head_price = peaks[0]

            # –ò—â–µ–º –ø–ª–µ—á–∏ - –≤–µ—Ä—à–∏–Ω—ã –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ
            shoulders = []
            for idx, price in peaks[1:]:
                # –ü–ª–µ—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ –∏ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã
                price_diff = abs(price - head_price) / head_price
                if price_diff > 0.15:  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —Å –≥–æ–ª–æ–≤–æ–π
                    continue

                shoulders.append((idx, price))

            if len(shoulders) >= 2:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –ø–ª–µ—á
                left_shoulder = min(shoulders, key=lambda x: x[0])
                right_shoulder = max(shoulders, key=lambda x: x[0])

                # –ü–ª–µ—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ —Ä–∞–∑–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ—Ç –≥–æ–ª–æ–≤—ã
                if left_shoulder[0] < head_idx < right_shoulder[0]:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –≤—ã—Å–æ—Ç –ø–ª–µ—á
                    shoulder_diff = abs(left_shoulder[1] - right_shoulder[1]) / max(left_shoulder[1], right_shoulder[1])

                    if shoulder_diff < 0.03:  # –ü–ª–µ—á–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω—ã –ø–æ –≤—ã—Å–æ—Ç–µ
                        return self._create_pattern_dict(
                            "–ì–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏",
                            "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                            "–í—ã—Å–æ–∫–∞—è",
                            "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ—Å–ª–µ –≤–æ—Å—Ö–æ–¥—è—â–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞",
                            "–ò—â–∏—Ç–µ –ø—Ä–æ–±–æ–π –ª–∏–Ω–∏–∏ —à–µ–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
                        )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–æ–ª–æ–≤—ã –∏ –ø–ª–µ—á: {e}")
            return None

    def _detect_double_top_bottom(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–≤–æ–π–Ω–æ–π –≤–µ—Ä—à–∏–Ω—ã –∏–ª–∏ –¥–Ω–∞
        üîç –î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞: –î–≤–µ –≤–µ—Ä—à–∏–Ω—ã –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ –ø–æ—Å–ª–µ —Ä–æ—Å—Ç–∞
        üîç –î–≤–æ–π–Ω–æ–µ –¥–Ω–æ: –î–≤–∞ –º–∏–Ω–∏–º—É–º–∞ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ –ø–æ—Å–ª–µ –ø–∞–¥–µ–Ω–∏—è
        """
        try:
            if len(df) < 20:
                return None

            high_prices = df['high'].values[-20:]
            low_prices = df['low'].values[-20:]

            # –ü–æ–∏—Å–∫ –¥–≤–æ–π–Ω–æ–π –≤–µ—Ä—à–∏–Ω—ã
            max1_idx = np.argmax(high_prices)
            max1_val = high_prices[max1_idx]

            # –ò—â–µ–º –≤—Ç–æ—Ä—É—é –≤–µ—Ä—à–∏–Ω—É, –∏—Å–∫–ª—é—á–∞—è –æ–±–ª–∞—Å—Ç—å –≤–æ–∫—Ä—É–≥ –ø–µ—Ä–≤–æ–π
            mask = np.ones_like(high_prices, dtype=bool)
            start_idx = max(0, max1_idx - 3)
            end_idx = min(len(high_prices), max1_idx + 4)
            mask[start_idx:end_idx] = False

            if np.any(mask):
                max2_val = np.max(high_prices[mask])
                max2_idx = np.where(high_prices == max2_val)[0][0]

                price_diff = abs(max1_val - max2_val) / max1_val
                time_diff = abs(max1_idx - max2_idx)

                if (price_diff < 0.02 and 5 <= time_diff <= 15):
                    return self._create_pattern_dict(
                        "–î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞",
                        "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                        "–°—Ä–µ–¥–Ω—è—è",
                        "–î–≤–µ –≤–µ—Ä—à–∏–Ω—ã –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è",
                        "–û–±—ä–µ–º –æ–±—ã—á–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç—Å—è –Ω–∞ –≤—Ç–æ—Ä–æ–π –≤–µ—Ä—à–∏–Ω–µ"
                    )

            # –ü–æ–∏—Å–∫ –¥–≤–æ–π–Ω–æ–≥–æ –¥–Ω–∞
            min1_idx = np.argmin(low_prices)
            min1_val = low_prices[min1_idx]

            mask = np.ones_like(low_prices, dtype=bool)
            start_idx = max(0, min1_idx - 3)
            end_idx = min(len(low_prices), min1_idx + 4)
            mask[start_idx:end_idx] = False

            if np.any(mask):
                min2_val = np.min(low_prices[mask])
                min2_idx = np.where(low_prices == min2_val)[0][0]

                price_diff = abs(min1_val - min2_val) / min1_val
                time_diff = abs(min1_idx - min2_idx)

                if (price_diff < 0.02 and 5 <= time_diff <= 15):
                    return self._create_pattern_dict(
                        "–î–≤–æ–π–Ω–æ–µ –¥–Ω–æ",
                        "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                        "–°—Ä–µ–¥–Ω—è—è",
                        "–î–≤–∞ –º–∏–Ω–∏–º—É–º–∞ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏",
                        "–û–±—ä–µ–º –æ–±—ã—á–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –≤—Ç–æ—Ä–æ–º –¥–Ω–µ"
                    )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–≤–æ–π–Ω–æ–π –≤–µ—Ä—à–∏–Ω—ã/–¥–Ω–∞: {e}")
            return None

    def _detect_triangle_patterns(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç—Ä–µ—É–≥–æ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        üîç –í–æ—Å—Ö–æ–¥—è—â–∏–π: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ + rising support
        üîç –ù–∏—Å—Ö–æ–¥—è—â–∏–π: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ + falling resistance
        üîç –°–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π: –°—Ö–æ–¥—è—â–∏–µ—Å—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ
        """
        try:
            if len(df) < 20:
                return None

            highs = df['high'].values[-20:]
            lows = df['low'].values[-20:]

            # –ê–Ω–∞–ª–∏–∑ –ª–∏–Ω–∏–π —Ç—Ä–µ–Ω–¥–∞
            high_slope = np.polyfit(range(len(highs)), highs, 1)[0]
            low_slope = np.polyfit(range(len(lows)), lows, 1)[0]

            if high_slope < -0.001 and low_slope > 0.001:
                return self._create_pattern_dict(
                    "–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ (–°–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π)",
                    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–°—Ö–æ–¥—è—â–∏–µ—Å—è –ª–∏–Ω–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è",
                    "–ü—Ä–æ–±–∏–≤–∞–µ—Ç –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞"
                )
            elif abs(high_slope) < 0.001 and low_slope > 0.001:
                return self._create_pattern_dict(
                    "–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ (–í–æ—Å—Ö–æ–¥—è—â–∏–π)",
                    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ + –≤–æ—Å—Ö–æ–¥—è—â–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞",
                    "–ë—ã—á–∏–π –ø—Ä–æ–±–æ–π –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–µ–Ω"
                )
            elif high_slope < -0.001 and abs(low_slope) < 0.001:
                return self._create_pattern_dict(
                    "–¢—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ (–ù–∏—Å—Ö–æ–¥—è—â–∏–π)",
                    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ + –Ω–∏—Å—Ö–æ–¥—è—â–µ–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ",
                    "–ú–µ–¥–≤–µ–∂–∏–π –ø—Ä–æ–±–æ–π –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–µ–Ω"
                )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞: {e}")
            return None

    def _detect_hammer_hanging_man(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤–µ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ú–æ–ª–æ—Ç –∏ –ü–æ–≤–µ—à–µ–Ω–Ω—ã–π
        üîç –ú–æ–ª–æ—Ç: –î–ª–∏–Ω–Ω–∞—è –Ω–∏–∂–Ω—è—è —Ç–µ–Ω—å, –º–∞–ª–µ–Ω—å–∫–æ–µ —Ç–µ–ª–æ (–±—ã—á–∏–π —Å–∏–≥–Ω–∞–ª –≤–Ω–∏–∑—É)
        üîç –ü–æ–≤–µ—à–µ–Ω–Ω—ã–π: –¢–æ –∂–µ, –Ω–æ –≤–≤–µ—Ä—Ö—É —Ç—Ä–µ–Ω–¥–∞ (–º–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª)
        """
        try:
            if len(df) < 3:
                return None

            latest = df.iloc[-1]
            prev_trend = self._get_short_term_trend(df)

            body_size = abs(latest['close'] - latest['open'])
            total_range = latest['high'] - latest['low']

            if total_range == 0:
                return None

            lower_shadow = min(latest['close'], latest['open']) - latest['low']
            upper_shadow = latest['high'] - max(latest['close'], latest['open'])

            shadow_ratio = lower_shadow / total_range
            body_ratio = body_size / total_range

            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            if (shadow_ratio > 0.6 and
                    upper_shadow / total_range < 0.2 and
                    body_ratio < 0.3):
                pattern_name = "–ú–æ–ª–æ—Ç" if prev_trend == 'down' else "–ü–æ–≤–µ—à–µ–Ω–Ω—ã–π"
                pattern_type = "–ë—ã—á–∏–π" if prev_trend == 'down' else "–ú–µ–¥–≤–µ–∂–∏–π"

                return self._create_pattern_dict(
                    pattern_name,
                    "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                    "–°—Ä–µ–¥–Ω—è—è",
                    f"{pattern_type} —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å –¥–ª–∏–Ω–Ω–æ–π –Ω–∏–∂–Ω–µ–π —Ç–µ–Ω—å—é",
                    "–¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–æ–π"
                )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–æ–ª–æ—Ç–∞/–ø–æ–≤–µ—à–µ–Ω–Ω–æ–≥–æ: {e}")
            return None

    def _detect_engulfing_patterns(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ü–æ–≥–ª–æ—â–µ–Ω–∏–µ
        üîç –ë—ã—á—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ: –ó–µ–ª–µ–Ω–∞—è —Å–≤–µ—á–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–≥–ª–æ—â–∞–µ—Ç –∫—Ä–∞—Å–Ω—É—é
        üîç –ú–µ–¥–≤–µ–∂—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ: –ö—Ä–∞—Å–Ω–∞—è —Å–≤–µ—á–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–≥–ª–æ—â–∞–µ—Ç –∑–µ–ª–µ–Ω—É—é
        """
        try:
            if len(df) < 3:
                return None

            latest = df.iloc[-1]
            prev = df.iloc[-2]

            # –ë—ã—á—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ
            if (latest['close'] > latest['open'] and  # –ë—ã—á—å—è —Å–≤–µ—á–∞
                    prev['close'] < prev['open'] and  # –ú–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞
                    latest['open'] < prev['close'] and  # –û—Ç–∫—Ä—ã—Ç–∏–µ –Ω–∏–∂–µ –∑–∞–∫—Ä—ã—Ç–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π
                    latest['close'] > prev['open']):  # –ó–∞–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ –æ—Ç–∫—Ä—ã—Ç–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π

                return self._create_pattern_dict(
                    "–ë—ã—á—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ",
                    "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ë—ã—á—å—è —Å–≤–µ—á–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–≥–ª–æ—â–∞–µ—Ç –º–µ–¥–≤–µ–∂—å—é",
                    "–°–∏–ª—å–Ω—ã–π —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–∏ –æ–±—ä–µ–º–µ"
                )

            # –ú–µ–¥–≤–µ–∂—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ
            elif (latest['close'] < latest['open'] and  # –ú–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞
                  prev['close'] > prev['open'] and  # –ë—ã—á—å—è —Å–≤–µ—á–∞
                  latest['open'] > prev['close'] and  # –û—Ç–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ –∑–∞–∫—Ä—ã—Ç–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π
                  latest['close'] < prev['open']):  # –ó–∞–∫—Ä—ã—Ç–∏–µ –Ω–∏–∂–µ –æ—Ç–∫—Ä—ã—Ç–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π

                return self._create_pattern_dict(
                    "–ú–µ–¥–≤–µ–∂—å–µ –ø–æ–≥–ª–æ—â–µ–Ω–∏–µ",
                    "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ú–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–≥–ª–æ—â–∞–µ—Ç –±—ã—á—å—é",
                    "–°–∏–ª—å–Ω—ã–π —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–∏ –æ–±—ä–µ–º–µ"
                )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–æ–≥–ª–æ—â–µ–Ω–∏—è: {e}")
            return None

    def _detect_doji_patterns(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –î–æ–¥–∂–∏
        üîç –î–æ–¥–∂–∏: –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ç–µ–ª–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ—Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        """
        try:
            latest = df.iloc[-1]

            body_size = abs(latest['close'] - latest['open'])
            total_range = latest['high'] - latest['low']

            if total_range == 0:
                return None

            body_ratio = body_size / total_range

            # –ö—Ä–∏—Ç–µ—Ä–∏–π –¥–æ–¥–∂–∏ - –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ç–µ–ª–æ
            if body_ratio < 0.1:
                return self._create_pattern_dict(
                    "–î–æ–¥–∂–∏",
                    "–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π",
                    "–ù–∏–∑–∫–∞—è",
                    "–°–≤–µ—á–∞ —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º —Ç–µ–ª–æ–º, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ—Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                    "–¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
                )

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥–æ–¥–∂–∏: {e}")
            return None

    def _detect_flag_pennant(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ñ–ª–∞–≥–æ–≤ –∏ –≤—ã–º–ø–µ–ª–æ–≤
        üîç –§–ª–∞–≥: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –ø–æ—Å–ª–µ —Å–∏–ª—å–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        üîç –í—ã–º–ø–µ–ª: –°—Ö–æ–¥—è—â–∏–µ—Å—è –ª–∏–Ω–∏–∏ (–º–∞–ª–µ–Ω—å–∫–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫)
        """
        try:
            if len(df) < 25:
                return None

            prices = df['close'].values[-25:]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–∏–ª—å–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è (–¥—Ä–µ–≤–∫–æ —Ñ–ª–∞–≥–∞)
            initial_move = abs(prices[0] - prices[10]) / prices[0]
            if initial_move < 0.05:  # –°–ª–∏—à–∫–æ–º —Å–ª–∞–±–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                return None

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é (–ø–æ–ª–æ—Ç–Ω–∏—â–µ —Ñ–ª–∞–≥–∞)
            consolidation_prices = prices[10:20]
            consolidation_range = (np.max(consolidation_prices) - np.min(consolidation_prices)) / np.mean(
                consolidation_prices)

            if consolidation_range < 0.02:  # –°–ª–∏—à–∫–æ–º —É–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
                return None

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            if consolidation_range > 0.08:  # –®–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω - –≤–µ—Ä–æ—è—Ç–Ω–æ —Ñ–ª–∞–≥
                return self._create_pattern_dict(
                    "–§–ª–∞–≥",
                    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ö–æ—Ä–æ—Ç–∫–∞—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–∏–ª—å–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è",
                    "–ü—Ä–æ–±–∏–≤–∞–µ—Ç –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è"
                )
            else:  # –£–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω - –≤–µ—Ä–æ—è—Ç–Ω–æ –≤—ã–º–ø–µ–ª
                return self._create_pattern_dict(
                    "–í—ã–º–ø–µ–ª",
                    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ",
                    "–í—ã—Å–æ–∫–∞—è",
                    "–ú–∞–ª–µ–Ω—å–∫–∏–π —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫ –ø–æ—Å–ª–µ —Å–∏–ª—å–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è",
                    "–ü—Ä–æ–±–∏–≤–∞–µ—Ç –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è"
                )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ñ–ª–∞–≥–∞/–≤—ã–º–ø–µ–ª–∞: {e}")
            return None

    def _get_short_term_trend(self, df: pd.DataFrame, period: int = 5) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞"""
        if len(df) < period + 1:
            return 'neutral'

        recent_prices = df['close'].values[-(period + 1):]
        price_change = recent_prices[-1] - recent_prices[0]

        if price_change > 0:
            return 'up'
        elif price_change < 0:
            return 'down'
        else:
            return 'neutral'

    def _create_pattern_dict(self, name: str, pattern_type: str,
                             confidence: str, description: str, easter_egg: str) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞—Ç—Ç–µ—Ä–Ω–µ"""
        return {
            "name": name,
            "type": pattern_type,
            "confidence": confidence,
            "description": description,
            "easter_egg": easter_egg,
            "timestamp": datetime.now().isoformat()
        }

    def _filter_patterns(self, patterns: List[Dict]) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        if not patterns:
            return []

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∏–º–µ–Ω–∏
        unique_patterns = {}
        for pattern in patterns:
            if pattern['name'] not in unique_patterns:
                unique_patterns[pattern['name']] = pattern

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–í—ã—Å–æ–∫–∞—è -> –°—Ä–µ–¥–Ω—è—è -> –ù–∏–∑–∫–∞—è)
        confidence_order = {'–í—ã—Å–æ–∫–∞—è': 3, '–°—Ä–µ–¥–Ω—è—è': 2, '–ù–∏–∑–∫–∞—è': 1}
        sorted_patterns = sorted(
            unique_patterns.values(),
            key=lambda x: confidence_order.get(x['confidence'], 0),
            reverse=True
        )

        return sorted_patterns

    def analyze_patterns_advanced(self, market_data: pd.DataFrame, patterns: List[Dict]) -> List[Dict]:
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞
        """
        if not patterns or market_data is None:
            return []

        advanced_analysis = []

        for pattern in patterns:
            try:
                analysis = {
                    'pattern_name': pattern['name'],
                    'pattern_type': pattern['type'],
                    'confidence': pattern['confidence'],
                    'trading_recommendations': self._generate_trading_recommendations(pattern, market_data),
                    'risk_metrics': self._calculate_risk_metrics(pattern, market_data),
                    'timeframe_suitability': self._assess_timeframe_suitability(pattern),
                    'volume_confirmation': self._check_volume_confirmation(market_data, pattern),
                    'pattern_strength': self._calculate_pattern_strength(pattern, market_data)
                }
                advanced_analysis.append(analysis)

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ {pattern.get('name')}: {e}")
                continue

        return advanced_analysis

    def _generate_trading_recommendations(self, pattern: Dict, df: pd.DataFrame) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        latest_price = df['close'].iloc[-1]

        recommendations = {
            'entry_price': self._calculate_entry_price(pattern, latest_price),
            'stop_loss': self._calculate_stop_loss(pattern, latest_price),
            'take_profit_1': self._calculate_take_profit(pattern, latest_price, 1),
            'take_profit_2': self._calculate_take_profit(pattern, latest_price, 2),
            'position_size': '1-2% –æ—Ç –¥–µ–ø–æ–∑–∏—Ç–∞',
            'risk_reward_ratio': '1:2.5',
            'timeframe': '4H-1D –¥–ª—è —Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã—Ö, 1H-4H –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è'
        }

        return recommendations

    def _calculate_entry_price(self, pattern: Dict, current_price: float) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–π —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞"""
        pattern_name = pattern['name']

        if any(x in pattern_name for x in ['–ú–æ–ª–æ—Ç', '–î–≤–æ–π–Ω–æ–µ –¥–Ω–æ', '–ë—ã—á—å–µ']):
            return round(current_price * 1.002, 4)  # –ù–∞ 0.2% –≤—ã—à–µ
        elif any(x in pattern_name for x in ['–ü–æ–≤–µ—à–µ–Ω–Ω—ã–π', '–î–≤–æ–π–Ω–∞—è –≤–µ—Ä—à–∏–Ω–∞', '–ú–µ–¥–≤–µ–∂—å–µ']):
            return round(current_price * 0.998, 4)  # –ù–∞ 0.2% –Ω–∏–∂–µ
        else:
            return round(current_price, 4)

    def _calculate_stop_loss(self, pattern: Dict, current_price: float) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ç–æ–ø-–ª–æ—Å—Å–∞"""
        if '–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π' in pattern['type']:
            return round(current_price * 0.97, 4)  # 3% —Å—Ç–æ–ø-–ª–æ—Å—Å
        else:
            return round(current_price * 0.98, 4)  # 2% —Å—Ç–æ–ø-–ª–æ—Å—Å

    def _calculate_take_profit(self, pattern: Dict, current_price: float, level: int = 1) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞"""
        if level == 1:
            multiplier = 1.05 if any(x in pattern['name'] for x in ['–ë—ã—á', '–ú–æ–ª–æ—Ç', '–î–Ω–æ']) else 0.95
        else:
            multiplier = 1.08 if any(x in pattern['name'] for x in ['–ë—ã—á', '–ú–æ–ª–æ—Ç', '–î–Ω–æ']) else 0.92

        return round(current_price * multiplier, 4)

    def _calculate_risk_metrics(self, pattern: Dict, df: pd.DataFrame) -> Dict:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞"""
        current_price = df['close'].iloc[-1]
        entry = self._calculate_entry_price(pattern, current_price)
        stop_loss = self._calculate_stop_loss(pattern, current_price)

        risk = abs(entry - stop_loss)
        reward = abs(self._calculate_take_profit(pattern, current_price, 1) - entry)
        risk_reward = reward / risk if risk > 0 else 0

        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        success_prob = 0.68 if pattern['confidence'] == '–í—ã—Å–æ–∫–∞—è' else 0.55 if pattern[
                                                                                   'confidence'] == '–°—Ä–µ–¥–Ω—è—è' else 0.45

        return {
            'risk_per_trade': round(risk, 4),
            'potential_reward': round(reward, 4),
            'risk_reward_ratio': f"1:{risk_reward:.1f}" if risk_reward > 0 else "1:0",
            'success_probability': f"{success_prob * 100:.0f}%"
        }

    def _assess_timeframe_suitability(self, pattern: Dict) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        if '–†–∞–∑–≤–æ—Ä–æ—Ç–Ω—ã–π' in pattern['type']:
            return {'1h': '–•–æ—Ä–æ—à–æ', '4h': '–û—Ç–ª–∏—á–Ω–æ', '1d': '–û—Ç–ª–∏—á–Ω–æ'}
        else:
            return {'1h': '–û—Ç–ª–∏—á–Ω–æ', '4h': '–•–æ—Ä–æ—à–æ', '1d': '–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ'}

    def _check_volume_confirmation(self, df: pd.DataFrame, pattern: Dict) -> str:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ–±—ä–µ–º–∞"""
        if len(df) < 10:
            return '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö'

        recent_volume = df['volume'].iloc[-5:].mean()
        avg_volume = df['volume'].iloc[-20:].mean()
        volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1

        if volume_ratio > 1.2:
            return '–°–∏–ª—å–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–±—ä–µ–º–æ–º'
        elif volume_ratio > 0.8:
            return '–£–º–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ'
        else:
            return '–°–ª–∞–±–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ'

    def _calculate_pattern_strength(self, pattern: Dict, df: pd.DataFrame) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∏–ª—ã –ø–∞—Ç—Ç–µ—Ä–Ω–∞ (0-100)"""
        strength = 50

        # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if pattern['confidence'] == '–í—ã—Å–æ–∫–∞—è':
            strength += 20
        elif pattern['confidence'] == '–°—Ä–µ–¥–Ω—è—è':
            strength += 10

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–±—ä–µ–º–æ–º
        volume_confirmation = self._check_volume_confirmation(df, pattern)
        if volume_confirmation == '–°–∏–ª—å–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–±—ä–µ–º–æ–º':
            strength += 15
        elif volume_confirmation == '–£–º–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ':
            strength += 5

        return min(100, max(0, strength))

    def get_patterns_cheatsheet(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —à–ø–∞—Ä–≥–∞–ª–∫—É –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º —Å –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        cheatsheet = []

        for name, info in self.pattern_descriptions.items():
            cheatsheet.append({
                "name": name,
                "type": info['type'],
                "description": info['description'],
                "reliability": info['reliability'],
                "volume_characteristics": info['volume'],
                "price_target": info['target'],
                "confirmation": info['confirmation'],
                "trading_tips": [
                    "–î–æ–∂–¥–∏—Ç–µ—Å—å –ø–æ–ª–Ω–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞",
                    "–ò—â–∏—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–±—ä–µ–º–æ–º",
                    "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ —Å—Ç–æ–ø-–ª–æ—Å—Å –Ω–∏–∂–µ/–≤—ã—à–µ –∫–ª—é—á–µ–≤—ã—Ö —É—Ä–æ–≤–Ω–µ–π",
                    "–¶–µ–ª–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏ - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ü–µ–ª–∏, –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω—É—é –ø—Ä–∏–±—ã–ª—å"
                ],
                "common_mistakes": [
                    "–¢–æ—Ä–≥–æ–≤–ª—è –¥–æ –ø–æ–ª–Ω–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞",
                    "–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–º–∞",
                    "–°–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏",
                    "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞"
                ]
            })

        return cheatsheet


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
pattern_detector = PatternDetector()


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def detect_patterns(market_data: pd.DataFrame) -> List[Dict]:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    return pattern_detector.detect_patterns(market_data)


def analyze_patterns_advanced(market_data: pd.DataFrame, patterns: List[Dict]) -> List[Dict]:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    return pattern_detector.analyze_patterns_advanced(market_data, patterns)


def get_patterns_cheatsheet() -> List[Dict]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —à–ø–∞—Ä–≥–∞–ª–∫–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
    return pattern_detector.get_patterns_cheatsheet()